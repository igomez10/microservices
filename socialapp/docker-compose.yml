version: "3.7"

networks:
  elk:
    name: docker-elk_elk

volumes:
  prometheus_data: {}
  grafana_data: {}
  db_data: {}
  kafka-data: {}
  kafka2_data: {}
  kafka3_data: {}
  # phlare_data: {}

services:
  database:
    image: debezium/postgres:15-alpine
    environment:
      POSTGRES_PASSWORD: password
      POSTGRES_DB: socialapp
    command:
      - postgres
      - -c
      - wal_level=logical
    volumes:
      - ./db/setup:/docker-entrypoint-initdb.d
      - ${DATABASE_DATA_DIR:-db_data}:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: always
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "database"
    cpus: 2
    mem_limit: 2g


  postgres-exporter:
    image: quay.io/prometheuscommunity/postgres-exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://postgres:password@database:5432/postgres?sslmode=disable"
    ports:
      - 9187:9187
    restart: unless-stopped
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "postgres-exporter"
    cpus: 0.5
    mem_limit: 512m

  grafana:
    image: grafana/grafana
    user: "472"
    ports:
      - 3005:3000
    environment:
      - GF_FEATURE_TOGGLES_ENABLE=flameGraph
      - POSTGRESQL_PROPERTIES_PASSWORD=${POSTGRESQL_PROPERTIES_PASSWORD}
      - POSTGRESQL_PASSWORD=${POSTGRESQL_PASSWORD}
      - GITHUB_ACCESSTOKEN=${GITHUB_ACCESSTOKEN}
      - GF_INSTALL_PLUGINS=redis-app
      - GF_INSTALL_PLUGINS=redis-explorer-app
    expose:
      - 3000
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    env_file:
      - ./grafana/config.monitoring
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 5s
      timeout: 5s
      retries: 5
    cpus: 0.5
    mem_limit: 512m
    # send logs to syslog
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "grafana"

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/:/etc/prometheus/
      - prometheus_data:/prometheus
    command:
      - '--storage.tsdb.retention.size=6GB'
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - 9090:9090
    expose:
      - 9090
    restart: always
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "prometheus"
  alertmanager:
    image: prom/alertmanager:latest
    volumes:
      - ./alertmanager/:/etc/alertmanager/
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
    ports:
      - 9093:9093
    expose:
      - 9093
    restart: always
    cpus: 2
    mem_limit: 2g
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "alertmanager"

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    privileged: true
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - /etc:/host/etc:ro
      - /var/run/dbus/system_bus_socket:/var/run/dbus/system_bus_socket
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      # enable process collector
      - '--collector.processes'
      #  enable systemd collector
      - '--collector.systemd'
    expose:
      - 9100
    ports:
      - 9100:9100
    cpus: 1
    mem_limit: 1024m
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "node-exporter"

  inspector:
    image: ubuntu:latest
    command: sleep infinity
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "inspector"

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.46.0
    container_name: monitoring_cadvisor
    privileged: true
    restart: unless-stopped
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    command:
      - '--docker_only=true'
      - '--housekeeping_interval=10s'
    expose:
      - 8080
    ports:
      - 8080:8080
    cpus: 2
    mem_limit: 4096m
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "cadvisor"

  broker:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://:9092,KRAFT://:9097,PLAINTEXT_HOST://:29092  # Both PLAINTEXT and KRAFT listeners
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092  # Only advertise the PLAINTEXT listener
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,KRAFT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: KRAFT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9097 #,2@localhost:9098
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: "yFMG3uNHSAKhz-zUrBIhjg"  # Base64-encoded UUID
    volumes:
      - kafka-data:/var/lib/kafka/data


  # broker2:
  #   image: confluentinc/cp-kafka:latest
  #   environment:
  #     KAFKA_BROKER_ID: 2
  #     KAFKA_LISTENERS: PLAINTEXT://:9093,KRAFT://:9098  # Both PLAINTEXT and KRAFT listeners
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9093  # Only advertise the PLAINTEXT listener
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,KRAFT:PLAINTEXT
  #     KAFKA_CONTROLLER_LISTENER_NAMES: KRAFT

  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  #     KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9097,2@localhost:9098
  #     KAFKA_NODE_ID: 2
  #     KAFKA_PROCESS_ROLES: broker,controller
  #     KAFKA_LOG_DIRS: /var/lib/kafka/data
  #     CLUSTER_ID: "yFMG3uNHSAKhz-zUrBIhjg"  # Base64-encoded UUID
  #   volumes:
  #     - kafka2_data:/var/lib/kafka/data
  
  # broker3:
  #   image: confluentinc/cp-kafka:7.3.0
  #   container_name: broker3
  #   environment:
  #     KAFKA_BROKER_ID: 3
  #     KAFKA_LISTENERS: PLAINTEXT://:9092
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9094
  #     KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9097,2@kafka2:9097,3@kafka3:9097
  #     KAFKA_NODE_ID: 3
  #     KAFKA_PROCESS_ROLES: broker,controller
  #   volumes:
  #     - kafka3_data:/var/lib/kafka/data



  # zookeeper:
  #   image: confluentinc/cp-zookeeper:7.3.0
  #   container_name: zookeeper
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   user: root
  #   volumes:
  #     - ${ZOOKEEPER_DATA_DIR}/data:/var/lib/zookeeper/data
  #     - ${ZOOKEEPER_DATA_DIR}/log:/var/lib/zookeeper/log
  #     - ${ZOOKEEPER_DATA_DIR}:/var/lib/zookeeper/data
  #   restart: always
  #   cpus: 0.5
  #   mem_limit: 512m
  #   logging:
  #     driver: "syslog"
  #     options:
  #       syslog-address: "udp://localhost:51000"
  #       tag: "zookeeper"
    

  # broker:
  #   image: confluentinc/cp-kafka:7.3.0
  #   container_name: broker
  #   ports:
  #     # To learn about configuring Kafka for access across networks see
  #     # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
  #     - "9092:9092"
  #     - "29092:29092"
  #     - "29093:29093"
  #   user: root
  #   volumes:
  #     - ${BROKER_DATA_DIR}:/var/lib/kafka/data
  #   # depends_on:
  #   #   - zookeeper
  #   environment:
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092
  #     KAFKA_LISTENERS: PLAINTEXT://:9092,PLAINTEXT_HOST://:29092
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_LOG_CLEANER_MAX_COMPACTION_LAG_MS: 21600000
  #     KAFKA_NUM_PARTITIONS: 3
  #     KAFKA_AUTO_LEADER_REBALANCE_ENABLE: "true"
  #   restart: always
  #   cpus: 1
  #   mem_limit: 2048m
  #   logging:
  #     driver: "syslog"
  #     options:
  #       syslog-address: "udp://localhost:51000"
  #       tag: "broker"
    

  # broker2:
  #   image: confluentinc/cp-kafka:7.3.0
  #   container_name: broker2
  #   depends_on:
  #     - zookeeper
  #   user: root
  #   ports:
  #     - 39092:39092
  #   environment:
  #     KAFKA_BROKER_ID: 2
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker2:9092,PLAINTEXT_HOST://localhost:39092
  #     KAFKA_LISTENERS: PLAINTEXT://:9092,PLAINTEXT_HOST://:39092
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_LOG_CLEANER_MAX_COMPACTION_LAG_MS: 21600000
  #     KAFKA_NUM_PARTITIONS: 3
  #     KAFKA_AUTO_LEADER_REBALANCE_ENABLE: "true"
  #   volumes:
  #     - ${BROKER2_DATA_DIR}:/var/lib/kafka/data
  #   restart: always
  #   cpus: 1
  #   mem_limit: 2048m
  #   logging:
  #     driver: "syslog"
  #     options:
  #       syslog-address: "udp://localhost:51000"
  #       tag: "broker2"


  # broker3:
  #   image: confluentinc/cp-kafka:7.3.0
  #   container_name: broker3
  #   user: root
  #   ports:
  #     - 49092:49092
  #   depends_on:
  #     - zookeeper
  #   environment:
  #     KAFKA_BROKER_ID: 3
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker3:9092,PLAINTEXT_HOST://localhost:49092
  #     KAFKA_LISTENERS: PLAINTEXT://:9092,PLAINTEXT_HOST://:49092
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_LOG_CLEANER_MAX_COMPACTION_LAG_MS: 21600000
  #     KAFKA_NUM_PARTITIONS: 3
  #     KAFKA_AUTO_LEADER_REBALANCE_ENABLE: "true"
  #   volumes:
  #     - ${BROKER3_DATA_DIR}:/var/lib/kafka/data
  #   restart: always
  #   cpus: 1
  #   mem_limit: 2048m
  #   logging:
  #     driver: "syslog"
  #     options:
  #       syslog-address: "udp://localhost:51000"
  #       tag: "broker3"


  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8095:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=broker:9092
    depends_on:
      - broker
      # - broker2
      # - broker3
    cpus: 0.5
    mem_limit: 512m
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "kafka-ui"

  integration-tests:
    build:
      context: .
      dockerfile: Integration.Dockerfile
    deploy:
      replicas: 2
    environment:
      "ADD_TEST_JITTER": 1,
      "TEST_SETUP": ${TEST_SETUP},
    restart: "unless-stopped"
    cpus: 0.5
    mem_limit: 512m
    logging:
      driver: "syslog"
      options:
        syslog-address: "udp://localhost:51000"
        tag: "integration-tests"

  # newrelic:
  #   build:
  #     context: ./newrelic
  #   container_name: newrelic
  #   volumes:
  #     - "/:/host:ro"
  #     - "/var/run/docker.sock:/var/run/docker.sock"
  #   cap_add:
  #     - SYS_PTRACE
  #   network_mode: host
  #   pid: host
  #   privileged: true
  #   environment:
  #     # set host name
  #     - NRIA_DISPLAY_NAME=ocivm
  #     - NRIA_OVERRIDE_HOSTNAME_SHORT=true
  #     - NRIA_LICENSE_KEY=${NEW_RELIC_LICENSE}
  #     - NEW_RELIC_LOG=stdout
  #     - NEW_RELIC_LOG_LEVEL=info

  elasticsearch-exporter:
    image: quay.io/prometheuscommunity/elasticsearch-exporter:latest
    environment:
      ELASTICSEARCH_PASSWORD: ${ELASTICSEARCH_PASSWORD}
      ELASTICSEARCH_USERNAME: ${ELASTICSEARCH_USERNAME}
    command:
      - '--es.uri=http://${ELASTICSEARCH_USERNAME}:${ELASTICSEARCH_PASSWORD}@elasticsearch:9200'
    restart: always
    networks:
      - elk
      - default
    depends_on:
      - prometheus
    ports:
      - "9114:9114"
    cpus: 0.5
    mem_limit: 512m

  # debezium:
  #   image: quay.io/debezium/connect:2.3
  #   ports:
  #     - 8083:8083
  #   environment:
  #     - BOOTSTRAP_SERVERS=broker:9092,broker2:9092,broker3:9092
  #     - GROUP_ID=1
  #     - CONFIG_STORAGE_TOPIC=debezium_storage_config
  #     - OFFSET_STORAGE_TOPIC=debezium_storage_offsets
  #     - STATUS_STORAGE_TOPIC=debezium_storage_status
  #   volumes:
  #     - ./debezium/plugins:/kafka/connect/plugins
  #     - ./debezium/config:/kafka/connect/config
  #   depends_on:
  #     - broker
  #     - broker2
  #     - broker3
  #     - zookeeper
  #     - database
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8083"]
  #     interval: 5s
  #     timeout: 5s
  #     retries: 5
  #   cpus: 2
  #   mem_limit: 4096m
  #   logging:
  #     driver: "syslog"
  #     options:
  #       syslog-address: "udp://localhost:51000"
  #       tag: "debezium"

  # debezium-ui:
  #   image: debezium/debezium-ui:latest
  #   container_name: debezium-ui
  #   ports:
  #     - "8084:8080"
  #   environment:
  #     - KAFKA_CONNECT_URIS=http://debezium:8083
  #   depends_on:
  #     - debezium
  #   restart: always
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8080"]
  #     interval: 5s
  #     timeout: 5s
  #     retries: 5
  #   cpus: 1
  #   mem_limit: 1024m
  #   logging:
  #     driver: "syslog"
  #     options:
  #       syslog-address: "udp://localhost:51000"
  #       tag: "debezium-ui"
